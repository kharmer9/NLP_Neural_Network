{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N64WWYPxMnyM"
   },
   "source": [
    "# IST 664 Final Project\n",
    "### Kevin Harmer\n",
    "This notebook was developed under the guidance of Lab 9 from the Syracuse iSchool's course IST 664. Model characteristics were also extracted from the Lab 10 of the same semester. While extracted from these labs, all code is directed toward the notebook's purpose. Also, I, Kevin Harmer, wrote all comments made in the code or in a surrounding text box to support project presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbApXyNklBpO"
   },
   "source": [
    "## Introduction\n",
    "The purpose of this project will be to write the first page of text in the style of Mark Twain. The text will be based off the two of Mark Twain's most popular novels: *Adventures of Huckleberry Finn* and *The Adventures of Tom Sawyer*. These online texts are available on gutenberg.org (exact links shown below and in references). The project is broken into several phases of development.\n",
    "\n",
    "The first two sections of the project work with data processing. Section 1 works with the data to convert the unstructured data from gutenberg into organized text data for evaluation. The goal for this section is to organize data into vector notation, which is machine readable for the notebook's models. Section 2 takes the imported data and organizes it into squences and datasets that can be used for the neural network models. The data at this point is hard to recognized relative to its initial text form.\n",
    "\n",
    "The third and fourth sections of the project concern model selection. In the development of a neural network model to write the final text, there are some analytics used to determine the best model. The third section deals with the development of three different neural networks: gated recurrent network, long short-term memory nework and a simple recurrent neural network. Once the models are developed, section 4 compares the three models, along with examining performance and accuracy among different epochs, embedding dimensions and neural network units.\n",
    "\n",
    "Based on the results from section 4, section 5 works with the development and training of a final model. This step recognizes the strengths of models and their associated testing parameters and uses the best results in development. Once compiled and trained, this model is used in the writing of the new book.\n",
    "\n",
    "Section 6 is dedicated to using the model from section 5 and generating it into text. The resulting neural network projects 2000 charcaters of text following the initial text of \"Chapter 1\", making it the first page of the computer-generated book.\n",
    "\n",
    "Getting into the notebook, we start with uploading all the modules used in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qf8NxTpAU0ch"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #model module\n",
    "from tensorflow import keras #layes of model development\n",
    "from tensorflow.keras.layers.experimental import preprocessing #data processing\n",
    "\n",
    "import numpy as np #numerical analysis\n",
    "import time #cell timing\n",
    "import matplotlib.pyplot as plt #used for model comparison\n",
    "\n",
    "from urllib import request #reading in data from url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlW2pL3yf4R0"
   },
   "source": [
    "## 1. Importing and Manipulating the Data\n",
    "Our first objective is obtaining the data. The following cells are used to import the text data from gutenberg.org.\n",
    "\n",
    "*Adventures of Huckleberry Finn* Text Url: https://www.gutenberg.org/files/76/76-0.txt\n",
    "\n",
    "*The Adventures of Tom Sawyer* Text Url: https://www.gutenberg.org/files/74/74-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rfODWTfPYiN3"
   },
   "outputs": [],
   "source": [
    "hf_url = \"https://www.gutenberg.org/files/76/76-0.txt\" #huckleberry finn\n",
    "hf_response = request.urlopen(hf_url)\n",
    "\n",
    "ts_url = \"https://www.gutenberg.org/files/74/74-0.txt\" #tom sawyer\n",
    "ts_response = request.urlopen(ts_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeZF5I2ObcUE",
    "outputId": "b47abbd1-e9ca-4746-cdb5-c16aea42b1c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546355"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the huckleberry finn text file\n",
    "hf_text = hf_response.read().decode('utf8') #entire huckleberry finn text\n",
    "#len(hf_text) #len for text measurments\n",
    "hf_text = hf_text[9572:] #removing all preliminary information up to chapter 1\n",
    "#len(hf_text) #len for text measurments\n",
    "hf_text = hf_text[:546355] #removing everything after the end of story; NEEDS TO BE AFTER INITIAL TEXT SPLIT\n",
    "len(hf_text) #final huckleberry finn text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJ-f_oHqd3_7",
    "outputId": "448da987-298a-4c37-932d-a9430f86a6f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_text = ts_response.read().decode('utf8') #entire tom sawyer text\n",
    "#len(ts_text) #len for text measurements\n",
    "ts_text = ts_text[7997:] #removing all preliminary information up to chapter 1\n",
    "#len(ts_text) #len for text measurements\n",
    "ts_text = ts_text[:394264] #removing everything after end of story; NEEDS TO BE AFTER INITIAL TEXT SPLIT\n",
    "len(ts_text) #final tom sawyer text length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HGaojXVvJMu"
   },
   "source": [
    "Once the data is imported, we start to convert it to machine readable data for analysis. The first step is organizing the characters of the text. These next few cells show the character analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ldNXNd3eBBZ",
    "outputId": "e4ad6327-fb97-4bed-f003-d377e0254b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huckleberry Finn has 77 unique characters.\n",
      "\n",
      "Tom Sawyer has 74 unique characters.\n"
     ]
    }
   ],
   "source": [
    "#Looking at input characters\n",
    "hf_vocab = sorted(set(hf_text)) #Huckleberry Finn Characters\n",
    "print(\"Huckleberry Finn has \" + str(len(hf_vocab)) + \" unique characters.\")\n",
    "ts_vocab = sorted(set(ts_text)) #Tom Sawyer Characters\n",
    "print(\"\\nTom Sawyer has \" + str(len(ts_vocab)) + \" unique characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLAoCpwUhTHP",
    "outputId": "fd29fab6-fd96-450d-d78a-cd1794b6c128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In both texts combined, there are a total of 81 unique characters.\n"
     ]
    }
   ],
   "source": [
    "#need to combine characters\n",
    "vocab = sorted(set(list(set(hf_text))+list(set(ts_text)))) #combining unique lists of text characters into sorted unique set of total characters\n",
    "print(\"In both texts combined, there are a total of \" + str(len(vocab)) + \" unique characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "altcut8plAgn",
    "outputId": "44218ef4-6d66-42d1-bf74-804f5b2ff7e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '\\r', ' ', '!', '$', '&', \"'\", '(', ')', '*']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLmWhd3iwtSv"
   },
   "source": [
    "It is important that the final vocab character set has inputs from both texts. The resulting text at the end should have input that looks like the first two texts and that is only accomplished with all the possible characters. With character lists, we start to vectorize the input. Specifically, the characters are now broken into character id tensors. These contain all the ids with each character (for numeric representation) along with a '[UNK]' key, which represents characters not located in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPg8pMTcifqm",
    "outputId": "7d7f5abb-3c14-419c-d6da-72abcbe408b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '\\n', '\\r', ' ', '!', '$', '&', \"'\", '(', ')'], 82)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting possible text inputs to vector layout with numerics for model analysis\n",
    "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab), mask_token=None) #ids from list of total vocab\n",
    "ids_from_chars.get_vocabulary()[:10], len(ids_from_chars.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N8zVID1sis3u"
   },
   "outputs": [],
   "source": [
    "#inversion function for ids; get characters from ids\n",
    "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B42tsB1olF-F"
   },
   "source": [
    "The preprocessed ids correspond to the correct characters from the book's combined vocab. They are identical other than '[UNK]', which represents a possible inputted unknown character. Now that our characters have been numerically described, we can convert the texts into these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cv-5MHuMknIU"
   },
   "outputs": [],
   "source": [
    "hf_chars = tf.strings.unicode_split(hf_text, input_encoding='UTF-8') #encoding huckleberry finn into tensor\n",
    "ts_chars = tf.strings.unicode_split(ts_text, input_encoding='UTF-8') #encoding tom sawyer into tensor\n",
    "#hf_chars[:10] #taking a look at the first 10 characters in tensor form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YRXB12u5NUPF"
   },
   "outputs": [],
   "source": [
    "hf_ids = ids_from_chars(hf_chars) #getting numeric ids from encoded tensor characters\n",
    "ts_ids = ids_from_chars(ts_chars)\n",
    "#hf_ids[:10] #previwing same ids from before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge8ZOsj0zIGT"
   },
   "source": [
    "With our set of ids, we have efficiently gathered all of the characters into tensors. With that, we can move onto the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkhRWH5RTBJC"
   },
   "source": [
    "## 2. Preparing Data for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNtpzBdJ479G"
   },
   "source": [
    "At this point, it is necessary to start organizing in the data in a way that is machine readable, even if it is not human readable. Firstly, the texts are combined. This is because our objective is to write a new sequence regardless of the specific point in the story. Additionally, the text will be shuffled later, so the order does not completely matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zD-x8sB2ACpR"
   },
   "outputs": [],
   "source": [
    "tottext = hf_text + ts_text\n",
    "num_char = len(tottext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NQCiCl1fYdzi"
   },
   "outputs": [],
   "source": [
    "hf_id_dataset = tf.data.Dataset.from_tensor_slices(hf_ids)\n",
    "ts_id_dataset = tf.data.Dataset.from_tensor_slices(ts_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WkxTnpZAAYFw"
   },
   "outputs": [],
   "source": [
    "chars = tf.strings.unicode_split(tottext, input_encoding='UTF-8') #converting texts to tensor\n",
    "ids = ids_from_chars(chars) #converting to ids based on tensor\n",
    "id_dataset = tf.data.Dataset.from_tensor_slices(ids) #using dataset from tensorflow to organize data; will be elaborated later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq0b_WY86HEd"
   },
   "source": [
    "With the combined text, we will now convert it to a set of sequences. These sequences will be analyzed individually. The models will be trained by these sequences and later generate similar sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gEHl9CV_SPiZ"
   },
   "outputs": [],
   "source": [
    "seq_length = 80 # 80 is about one line of standard text; 60 and 100 tested, but 80 led to best model\n",
    "hf_sequences = hf_id_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "ts_sequences = ts_id_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "sequences = id_dataset.batch(seq_length+1, drop_remainder=True) #generating batchs of sequences with length designated above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W1QYHAN7MG-"
   },
   "source": [
    "The following block of code is taken from lab 9, with added original comments. The purpose of the code is to take the sequences and split them into a training set of sequences, then pair them with each of their following sequences. The result is then mapped into an entire data structure, which is labeled \"dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-_ileS0kTxoP"
   },
   "outputs": [],
   "source": [
    "#following function taken from Lab 9\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1] #input text; initial sequences in data\n",
    "    target_text = sequence[1:] #target text; exactly one sequence after input sequence\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nMi7OlAsVcC1"
   },
   "outputs": [],
   "source": [
    "hf_dataset = hf_sequences.map(split_input_target)\n",
    "ts_dataset = ts_sequences.map(split_input_target)\n",
    "dataset = sequences.map(split_input_target) #developing data set with sequence to sequence pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq6dJnOm8JG1"
   },
   "source": [
    "Now that we have a data set of initial sequences to sequences immediately following the sequence, we can shuffle the sequences. This is important so that the dataset has some randomization of prediction to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gfmEWEgkVwla"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "hf_buffer = len(hf_text)\n",
    "ts_buffer = len(ts_text)\n",
    "buffer_size = len(tottext)\n",
    "\n",
    "hf_dataset = dataset.shuffle(hf_buffer).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ts_dataset = dataset.shuffle(ts_buffer).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset = hf_dataset.concatenate(ts_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4YcTRHpYk5G"
   },
   "source": [
    "## 3. Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxUORP-u-wEd"
   },
   "source": [
    "Now that the data has been prepared for models, we can move into the model development. Firstly, we define a few parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9x2PI00QXk45"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(chars_from_ids.get_vocabulary()) #number of unique characters\n",
    "embedding_dim = len(chars_from_ids.get_vocabulary()) #number of embedding vector dimensions; possible overfitting when exceeding vocab size\n",
    "rnn_units = 4*len(chars_from_ids.get_vocabulary()) #nodes for embedding layers (enough for 4 nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fem9y5qJ-5-b"
   },
   "source": [
    "The vocab size represents the amount of characters in the data set, the embedding dimension represents how in depth the embedding will be, and the rnn_units determine how many features the model can represent. In testing, embedding size was tested with twice the vocab_size and rnn_units was tested with anywhere from the embedding dimension to 20x the embedding dimension. The best results were embedding exactly at the vocab size and the rnn units about 10 times the size of the embedding dimension. The listed values, however, were used for model comparison.\n",
    "\n",
    "Moving forwards, we will next build the actual models used for analysis. The following two models were developed using the models found in Lab 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "baDpauYDb1Fx"
   },
   "outputs": [],
   "source": [
    "class RNNmodel(tf.keras.Model): #School of Information Studies, 2022\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units, rnn_type = \"RNN\"):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #embedding tensorflow layer\n",
    "    if rnn_type==\"RNN\": #run simple rnn; model 1\n",
    "      #simple RNN model with returned sequences and states to grow from previous vaulues\n",
    "      self.rnn = tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True,return_state=True)\n",
    "    elif rnn_type == \"GRU\": #run GRU; model 2\n",
    "      #GRU model with returned sequences and states to grow from previous vaulues\n",
    "      self.rnn = tf.keras.layers.GRU(rnn_units,return_sequences=True,return_state=True)\n",
    "    else:\n",
    "      print(\"Type of Neural Network not Specificed. Please select 'RNN' or 'GRU'.\")\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size) #bring the dimesions of internal layers back to the vocab size\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs #redfining alias\n",
    "    x = self.embedding(x, training=training) #embedding the input baesd on training set\n",
    "    if states is None:\n",
    "      states = self.rnn.get_initial_state(x) #checking for initial states\n",
    "    x, states = self.rnn(x, initial_state=states, training=training) #applying initial states if any\n",
    "    x = self.dense(x, training=training) #applying to entire model\n",
    "    if return_state: #checking return state\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Z4fpl04PaXQ7"
   },
   "outputs": [],
   "source": [
    "class LSTMmodel(keras.Model): #School of Information Studies, 2022\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #embedding layer\n",
    "    self.rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True,return_state=True) #run LSTM; model 1\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size) #Dense Layer\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    #similar to other model\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.rnn.get_initial_state(x)\n",
    "    x, states1, states2 = self.rnn(x, initial_state = states, training = training)\n",
    "    x = self.dense(x, training=training)\n",
    "    if return_state:\n",
    "      return x, states1, states2\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2C4ePHfNIEA"
   },
   "source": [
    "With defined models, we can move into the actual development of our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "H7Mi02T39k2R"
   },
   "outputs": [],
   "source": [
    "model1 = RNNmodel(vocab_size=vocab_size, #simple RNN model\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model2 = RNNmodel(vocab_size=vocab_size, #GRU model\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    rnn_type = \"GRU\")\n",
    "\n",
    "model3 = LSTMmodel(vocab_size=vocab_size, #LSTM model\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "# The following code is to help build the model; running the data set through\n",
    "# an iteration of each model teaches the model what the input data will be.\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions1 = model1(input_example_batch)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions2 = model2(input_example_batch)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions3 = model3(input_example_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lei4u6tgNPKR"
   },
   "source": [
    "Which lead to the model framework found in the following three cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPtFYKMB_FWC",
    "outputId": "f95d9b8d-5d78-4fa7-fafc-77e2a876b6f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rn_nmodel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  6724      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      multiple                  134808    \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  26978     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,510\n",
      "Trainable params: 168,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBXsBpheVK_v",
    "outputId": "77ca5539-9a93-4a78-f420-1710493ac013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rn_nmodel_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  6724      \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  405408    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  26978     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 439,110\n",
      "Trainable params: 439,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RrUwkjpft82",
    "outputId": "2a09d405-1a42-4a32-9dec-6c4f5c5559a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lst_mmodel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     multiple                  6724      \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  539232    \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  26978     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 572,934\n",
      "Trainable params: 572,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ3ueQdYCW-d"
   },
   "source": [
    "## 4. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH8nV4WpOFdg"
   },
   "source": [
    "Now that the framework of the models have been constructed, we can finally move into the data training and ultimately select a model. We begin by compiling each of the models using a crossentropy log loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rWgjgxQ3CWS_"
   },
   "outputs": [],
   "source": [
    "# setting the loss analysis\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model1.compile(optimizer='adam', loss=loss)\n",
    "model2.compile(optimizer='adam', loss=loss)\n",
    "model3.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfS1_Rz9OZuW"
   },
   "source": [
    "Then, we fit the following models. This is the step which requires the most parameter fluctuation. Parameters have been tuned and adjusted. The final parameters for display help the reader view the ultimate results of each model, leading to the model selection in the next section. *Note:* GPU Accelerator Recommended for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xAhmIDm-rBH",
    "outputId": "080ad592-fdb1-4142-fff3-2bd3d069cc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 9s 72ms/step - loss: 2.9060\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 2.2149\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 2.0253\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 1.9004\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 1.8062\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 1.7332\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 1.6755\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 1.6275\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 9s 81ms/step - loss: 1.5874\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 9s 74ms/step - loss: 1.5541\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 1.5247\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 1.5003\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 1.4779\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 8s 71ms/step - loss: 1.4582\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 9s 75ms/step - loss: 1.4394\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 8s 69ms/step - loss: 1.4235\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 8s 68ms/step - loss: 1.4101\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 8s 67ms/step - loss: 1.3955\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 8s 68ms/step - loss: 1.3834\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 8s 68ms/step - loss: 1.3707\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 3s 11ms/step - loss: 3.2357\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 2.4196\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.1937\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 2.0474\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.9133\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 1.8009\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.7084\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 1.6352\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 1.5738\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.5234\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.4808\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.4437\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.4122\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.3842\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.3588\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.3369\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.3161\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.2978\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.2798\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 2s 10ms/step - loss: 1.2629\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 3s 13ms/step - loss: 3.1773\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 2.4669\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 2.2261\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 2.1042\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 2.0097\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.9283\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.8612\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 1.8061\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.7591\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.7180\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.6821\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.6490\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.6203\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 1.5939\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.5697\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.5474\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 1.5269\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 1.5075\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 2s 12ms/step - loss: 1.4906\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 1.4726\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(dataset, epochs=20)\n",
    "history2 = model2.fit(dataset, epochs=20)\n",
    "history3 = model3.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3NWs0TPPBW_"
   },
   "source": [
    "Now that each of models have been trained, we can view their statistics. The GRU model ended in the lowest final loss, indicating that it may be the strongest model. As for performance, LSTM was the worst performing, and Simple RNN was the best performing, but the difference was not significant enough to exclude a model. Let's review the distribution of logit loss over per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "lKsvtVgoLZPW",
    "outputId": "30c5af73-3417-4034-be89-1a9f5560ad14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f57e9ff91d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history1.history[\"loss\"], c = 'b', label='RNN')\n",
    "plt.plot(history2.history[\"loss\"], c = 'r', label='GRU')\n",
    "plt.plot(history3.history[\"loss\"], c = 'g', label='LSTM')\n",
    "plt.title(\"Model Loss Analysis\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "#initial observations favor Simple Reccurent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zY8MWrpPduW"
   },
   "source": [
    "After Epoch 5, the GRU model appeared to be the best performing model. GRU was also consistently the best over most the parameter training. Therefore, we will use a GRU variation model for the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUj6ZawQBb6c"
   },
   "source": [
    "## 5. Compiling and Training Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXKTQnTjSkAE"
   },
   "source": [
    "As discussed from in the previous cell, we will be using the GRU model which was analyzed previously. After parameter testing, the embedding dimension is best where it is at. RNN units, on the other hand, is best with 32 times the embedding dimension, or 32 nodes in the system. Increasing the rnn units decreased the loss until around 34. Furthermore, increasing the sequence length to 100 (increasing the amount of input per point), also decreased the loss, leading to that adjustment. With those values, the final model was was constructed, compiled, then trained. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHeYKWKnBbVd",
    "outputId": "060e533a-ac2a-41c9-bd52-e85b3833e944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "362/362 [==============================] - 56s 127ms/step - loss: 2.3794\n",
      "Epoch 2/15\n",
      "362/362 [==============================] - 48s 129ms/step - loss: 1.6279\n",
      "Epoch 3/15\n",
      "362/362 [==============================] - 48s 129ms/step - loss: 1.3700\n",
      "Epoch 4/15\n",
      "362/362 [==============================] - 48s 129ms/step - loss: 1.2078\n",
      "Epoch 5/15\n",
      "362/362 [==============================] - 48s 129ms/step - loss: 1.0436\n",
      "Epoch 6/15\n",
      "362/362 [==============================] - 48s 130ms/step - loss: 0.8451\n",
      "Epoch 7/15\n",
      "362/362 [==============================] - 47s 126ms/step - loss: 0.6299\n",
      "Epoch 8/15\n",
      "362/362 [==============================] - 48s 130ms/step - loss: 0.4501\n",
      "Epoch 9/15\n",
      "362/362 [==============================] - 47s 126ms/step - loss: 0.3383\n",
      "Epoch 10/15\n",
      "362/362 [==============================] - 48s 129ms/step - loss: 0.2841\n",
      "Epoch 11/15\n",
      "362/362 [==============================] - 47s 128ms/step - loss: 0.2717\n",
      "Epoch 12/15\n",
      "362/362 [==============================] - 46s 125ms/step - loss: 0.2830\n",
      "Epoch 13/15\n",
      "362/362 [==============================] - 46s 125ms/step - loss: 0.2947\n",
      "Epoch 14/15\n",
      "362/362 [==============================] - 47s 126ms/step - loss: 0.3096\n",
      "Epoch 15/15\n",
      "362/362 [==============================] - 47s 126ms/step - loss: 0.3273\n"
     ]
    }
   ],
   "source": [
    "final_model = RNNmodel(vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=6*rnn_units, #8 times original rnn_units, leading to 32 times the embedding dimension\n",
    "    rnn_type = \"GRU\") #GRU model result; now 32 rnn nodes\n",
    "\n",
    "final_model.compile(optimizer='adam', loss=loss)\n",
    "history = final_model.fit(dataset, epochs=15) #WARNING: may take long time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYics8gTENcV"
   },
   "source": [
    "## 6. Generating Text From Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqnGdg6TUpWy"
   },
   "source": [
    "Now that we have our model, which is designed to model the writing of Mark Twain, we can finally write our new Mark Twain book. The next set of code is derived from Lab 10 once again, with the purpose of predicting text based on the previous text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7M2v_5o0DNQK"
   },
   "outputs": [],
   "source": [
    "class New(tf.keras.Model): #School of Information Studies, 2022\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temp=1.0):\n",
    "    super().__init__()\n",
    "    self.temp = temp #scaling coefficient\n",
    "    self.model = model #model used to produce text\n",
    "    self.chars_from_ids = chars_from_ids #characters from indices input\n",
    "    self.ids_from_chars = ids_from_chars #indices from characters input\n",
    "\n",
    "    mask_ids = self.ids_from_chars(['[UNK]'])[:, None] #unknown character mask\n",
    "    sparse_mask = tf.SparseTensor(values=[-float('inf')]*len(mask_ids), #all text before to current text\n",
    "        indices=mask_ids, #current text\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())]) #shape of matrix given vocab size\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask) #tf mask\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8') #input text to convert to characters\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor() #getting characters and converting to ids\n",
    "\n",
    "    pred_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True) #logit predictions\n",
    "\n",
    "    pred_logits = pred_logits[:, -1, :] #using most recent prediction\n",
    "    pred_logits = pred_logits/self.temp #scaling prediction\n",
    "\n",
    "    pred_logits = pred_logits + self.prediction_mask #masking term\n",
    "\n",
    "    pred_ids = tf.random.categorical(pred_logits, num_samples=1) #generating predicted ids\n",
    "    pred_ids = tf.squeeze(pred_ids, axis=-1)\n",
    "    pred_chars = self.chars_from_ids(pred_ids) #returning to characters\n",
    "    \n",
    "    return pred_chars, states #returning text and state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zUemEQcZuTX"
   },
   "source": [
    "Now that the model is compiled, we can incorporate the trained model and run it with our data. The temperature is adjusted based on the desired randomness in the data. Observationally, 1.0 appeared to have the best writen result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "39mz7JNVFYL5"
   },
   "outputs": [],
   "source": [
    "newbook = New(final_model, chars_from_ids, ids_from_chars, temp = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF0TrVwAbBSd"
   },
   "source": [
    "Now that text generation model is complete, we can start viewing text from the new book! The first 2000 characters are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2OZceApFf14",
    "outputId": "172be3d9-fa85-4ddb-d08a-03ce5d8b65c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "CHAPTER I.\r\n",
      "\r\n",
      "\r\n",
      "A bringing stared and chap, and a snake-skinned nothing. “The whole fight now! I won’t betry and tell you what's\r\n",
      "going on they every day if they get back to the widow’s baggles. That’ll be a good boy.”\r\n",
      "\r\n",
      "Says If get me worse. After with her ifas' hands considered a miserab endures wishing him and A\r\n",
      "new-caustry and snoress as they walled; and told me to come back. This well night. They gained on the\r\n",
      "ferry landing, and there was no window was upter some conspicuous eight now ex to tell on it. It set down in\r\n",
      "dewn he would slip over all this outfroken search would be in a man on the tribe of Grangerfords, and frocks entirely.\r\n",
      "\r\n",
      "But Stands for the family would say their pipes and powerful jacter. The old lady seas it was a good name and scratched out a\r\n",
      "pie and the hat church. He said I wished I was glad I hadn't fell day. Con you going\r\n",
      "to camp from grought on the table end of the floor and old rat he older\r\n",
      "up any more--both or our house; and if you're abroading a pipon without saying a year.\r\n",
      "\r\n",
      "But in that hard a said something of interest to possesting something to see why I couldn't stand my scrape; but she tried to get\r\n",
      "out on the grass in the world to me with enevily by and by. Muchadsem, he\r\n",
      "said:\r\n",
      "\r\n",
      "“Why, my boy, you are a targe’t aight of it. And all that?”\r\n",
      "\r\n",
      "“It’s our old rush of Muff Potter’s pop' mile below the window—but the quarter was still as putting\r\n",
      "hating themselves worried over it. She was smiless heart of the church, and her\r\n",
      "face got through the hands of the jeal-that he had beenthant too grown that was his voice; then he\r\n",
      "dropped the writts and went searing against him by the thinnes. The dicken\r\n",
      "right on a relie quiet with the empty aise supper—the stoles of the church’s eyes conveniently; he made a so\r\n",
      "bad luck that the boys had a long slow bit out of one of his active at time, and takened him\r\n",
      "on with indance to him, and he was half suppy; and as he dropped in behind. His heart was gone\r\n",
      "and we wanted him to go achore in the water. When  \n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant([\"\\r\\n\\r\\n\\r\\nCHAPTER I.\\r\\n\\r\\n\\r\\n\"])\n",
    "result = [next_char] #starting with \"Chapter I.\"\n",
    "\n",
    "for n in range(2000): #first 200 characters; about first page\n",
    "  next_char, states = newbook.generate_one_step(next_char, states=states) #gnerating the next step of text from the initial (to end)\n",
    "  result.append(next_char) #appending result into text\n",
    "\n",
    "result = tf.strings.join(result) #joining all of the resulting strings\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80) #printing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unt7abGsbtwN"
   },
   "source": [
    "## Conclusion\n",
    "Once the text is generated, our objective is complete! Several coherent paragraphs of text are exactly what we are looking for. Overall, the book appears to be in good shape relative to the training methods. Although it is not perfect grammatically, the text does appear to be written with an underlying plot and purpose. Although it may seem confusing at first glance, Mark Twain himself was not always the clearest in his writing; the test does appear to resemble him partially.\n",
    "\n",
    "So, the output was successful in the objective. Along with coherent sentences, sentences and paragraphs seem to be somewhat related. But how can it be better or include a larger plotline with Huckleberry Finn and Tom Sawyer? Running the model with a larger data set of books or increasing the memory layers would likely decrease the loss, thus supporting the overall quality of the text. Specifically, if the model trained with more books written by Mark Twain about the two main characters would surely improve the models. Furthermore, adding additional layers to the models would likely improve the memories linking the text much more efficiently. Also, generating more text, in general, may help the plot develop as well. The text seems to be from Huckleberry Finn's perspective and mentions Tom in the text as well (may change based on run instance).\n",
    "\n",
    "Expanding this concept, this method could surely be used for other authors. Moving forward, the model structure could be documented then incorporated into some designated function. This function could take in text data, train it with its variations, then return new similar text. Using other authors and other books, especially those from gutenberg, may help with the development of new stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqFb9-fci4m3"
   },
   "source": [
    "## References\n",
    "- School of Infomation Studies. (2022, Spring). IST 664 Lab 9 Notebook. Syracuse, New York: Syracuse University. Retrieved from class website at https://blackboard.syracuse.edu/bbcswebdav/pid-7942130-dt-content-rid-88619002_1/xid-88619002_1.\n",
    "- School of Infomation Studies. (2022, Spring). IST 664 Lab 10 Notebook. Syracuse, New York: Syracuse University. Retrieved from class website at https://blackboard.syracuse.edu/bbcswebdav/pid-7954325-dt-content-rid-88999200_1/xid-88999200_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iwm0xnmbn0KT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0VwAreR8VIjD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "IST664_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
